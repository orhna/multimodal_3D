{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e37317be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from os.path import join, exists\n",
    "import open3d as o3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d14cb79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# should be the preprocessed file path\n",
    "sample_path_0 = \"D:/AT3DCV_Data/Preprocessed_OpenScene/data/scannet_3d/train/scene0000_00_vh_clean_2.pth\"\n",
    "#sample_path_1 = \"D:/AT3DCV_Data/Preprocessed_OpenScene/data/scannet_3d/train/scene0000_01_vh_clean_2.pth\"\n",
    "#sample_path_2 = \"D:/AT3DCV_Data/Preprocessed_OpenScene/data/scannet_3d/train/scene0000_02_vh_clean_2.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5de5eb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_0 = torch.load(sample_path_0) # coords,colors,labels\n",
    "#sample_1 = torch.load(sample_path_1) # coords,colors,labels\n",
    "#sample_2 = torch.load(sample_path_2) # coords,colors,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64d69828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81369"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sample_0[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d643bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregating all of the partial point clouds of the same scene (they don't overlap perfectly)\n",
    "#sample_points = np.concatenate((sample_0[0], sample_1[0], sample_2[0]))\n",
    "#sample_colors = np.concatenate((sample_0[1], sample_1[1], sample_2[1]))\n",
    "\n",
    "# single partial point cloud\n",
    "sample_points  = sample_0[0]\n",
    "sample_colors = sample_0[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f6663b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to view original scene\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(np.asarray(sample_points))\n",
    "#original colors\n",
    "pcd.colors = o3d.utility.Vector3dVector(np.asarray(sample_colors))\n",
    "#------\n",
    "#paint uniform\n",
    "#sample_paint_uniform = np.asarray([200,200,200])/255.0 #redish\n",
    "#pcd.paint_uniform_color(sample_paint_uniform)\n",
    "o3d.visualization.draw_geometries([pcd])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5135af0",
   "metadata": {},
   "source": [
    "# load fused features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "212cf156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# should be the fused feature path\n",
    "feature_path = \"D:/AT3DCV_Data/Preprocessed_OpenScene/data/scannet_fused_features/test_whole/scene0000_00_0.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc7f5bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = torch.load(feature_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b12fcc98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([81369])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature[\"mask_full\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f474ddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([77681, 768])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature[\"feat\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18fc2d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the indices where the mask is True\n",
    "indices = torch.nonzero(feature[\"mask_full\"]).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65077247",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_point_cloud = sample_points[indices, :]\n",
    "filtered_point_cloud_colors = sample_colors[indices, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5798734e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77681, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_point_cloud.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afd5dbb",
   "metadata": {},
   "source": [
    "# using clip model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a01ad33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import clip\n",
    "model, preprocess = clip.load(\"ViT-L/14@336px\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "03cd8fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# type the query here \n",
    "query = [\"floor\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f56a8260",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 20.59it/s]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    all_text_embeddings = []\n",
    "    for category in tqdm(query):\n",
    "        texts = clip.tokenize(category)  #tokenize\n",
    "        texts = texts.cuda()\n",
    "        text_embeddings = model.encode_text(texts)  #embed with text encoder\n",
    "        text_embeddings /= text_embeddings.norm(dim=-1, keepdim=True)\n",
    "        text_embedding = text_embeddings.mean(dim=0)\n",
    "        text_embedding /= text_embedding.norm()\n",
    "        all_text_embeddings.append(text_embedding)\n",
    "\n",
    "    all_text_embeddings = torch.stack(all_text_embeddings, dim=1)\n",
    "\n",
    "# calculating similarity matrix\n",
    "similarity_matrix = torch.matmul(feature[\"feat\"].cuda(), all_text_embeddings) # \n",
    "\n",
    "# set higher to increase the certainty (not always correct)\n",
    "threshold_percentage = 0.4\n",
    "cap = similarity_matrix.max().item()\n",
    "found_indices = torch.nonzero(similarity_matrix > cap*threshold_percentage, as_tuple=False).squeeze().T[0]\n",
    "\n",
    "# creating pc\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(np.asarray(filtered_point_cloud))\n",
    "pcd.colors = o3d.utility.Vector3dVector(np.asarray(filtered_point_cloud_colors))\n",
    "\n",
    "found_region = pcd.select_by_index(found_indices.tolist())\n",
    "found_region.paint_uniform_color([1.0, 0, 0]) # paint related points to red\n",
    "rest = pcd.select_by_index(found_indices.tolist(), invert=True)\n",
    "o3d.visualization.draw_geometries([rest,found_region])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61753a16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
