{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6762eeac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from os.path import join, exists\n",
    "import open3d as o3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fc789ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "original = \"/mnt/project/AT3DCV_Data/Preprocessed_OpenScene/data/scannet_3d/example/scene0000_00_vh_clean_2.pth\"\n",
    "# need to have distilled features ready\n",
    "distilled_features = \"/mnt/project/AT3DCV_Data/3D_features/scene0000_00_vh_clean_2_openscene_feat_distill.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eea46dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_sample = torch.load(original) \n",
    "original_sample_points  = original_sample[0]\n",
    "original_sample_colors = original_sample[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f708376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81369"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(original_sample[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9a784ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to view original scene\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(np.asarray(original_sample_points))\n",
    "#original colors\n",
    "pcd.colors = o3d.utility.Vector3dVector(np.asarray(original_sample_colors))\n",
    "#------\n",
    "#paint uniform\n",
    "#sample_paint_uniform = np.asarray([200,200,200])/255.0 #redish\n",
    "#pcd.paint_uniform_color(sample_paint_uniform)\n",
    "o3d.visualization.draw_geometries([pcd])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7302321f",
   "metadata": {},
   "source": [
    "# load distilled features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "714541a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just load, no need for masking since we have distilled features for every 3D point\n",
    "distilled = np.load(distilled_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e29694",
   "metadata": {},
   "source": [
    "# using clip model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2c1fdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import clip\n",
    "model, preprocess = clip.load(\"ViT-L/14@336px\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e5cfa9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# type the query here \n",
    "query = [\"bed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adf30c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 32.92it/s]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    all_text_embeddings = []\n",
    "    for category in tqdm(query):\n",
    "        texts = clip.tokenize(category)  #tokenize\n",
    "        texts = texts.cuda()\n",
    "        text_embeddings = model.encode_text(texts)  #embed with text encoder\n",
    "        text_embeddings /= text_embeddings.norm(dim=-1, keepdim=True)\n",
    "        text_embedding = text_embeddings.mean(dim=0)\n",
    "        text_embedding /= text_embedding.norm()\n",
    "        all_text_embeddings.append(text_embedding)\n",
    "\n",
    "    all_text_embeddings = torch.stack(all_text_embeddings, dim=1)\n",
    "\n",
    "#cast and normalize embeddings\n",
    "distilled_t = torch.from_numpy(distilled).half()\n",
    "distilled_t = distilled_t / distilled_t.norm(p=2, dim=-1, keepdim=True)\n",
    "\n",
    "# calculating similarity matrix\n",
    "similarity_matrix = torch.matmul(distilled_t.cuda(), all_text_embeddings) # \n",
    "\n",
    "# set higher to increase the certainty (not always correct)\n",
    "threshold_percentage = 0.4\n",
    "cap = similarity_matrix.max().item()\n",
    "found_indices = torch.nonzero(similarity_matrix > cap*threshold_percentage, as_tuple=False).squeeze().T[0]\n",
    "\n",
    "# creating pc\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(np.asarray(original_sample_points))\n",
    "pcd.colors = o3d.utility.Vector3dVector(np.asarray(original_sample_colors))\n",
    "\n",
    "found_region = pcd.select_by_index(found_indices.tolist())\n",
    "found_region.paint_uniform_color([1.0, 0, 0]) # paint related points to red\n",
    "rest = pcd.select_by_index(found_indices.tolist(), invert=True)\n",
    "o3d.visualization.draw_geometries([rest,found_region])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b148ce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4947])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "found_indices.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
