{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f6965b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "import torch\n",
    "import numpy as np\n",
    "import objaverse\n",
    "import multiprocessing\n",
    "from PIL import Image\n",
    "import io\n",
    "from matplotlib import pyplot as plt\n",
    "from os import path\n",
    "import os\n",
    "import shutil\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ced6bdd",
   "metadata": {},
   "source": [
    "# transforming object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b7222f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#uid = 'febdbce61b45472da3de7d9a9878ef7a'\n",
    "\n",
    "# Nicobar Pigeon  40 cm\n",
    "uid1 = \"a995d6f5ea674aa7a7365d5372176b95\"\n",
    "# Eastern Rosella 30 cm\n",
    "uid2 = \"f3c9b82285c24ad6b8f683d285c9cd6c\"\n",
    "\n",
    "model_annot = objaverse.load_annotations([uid1,uid2])\n",
    "\n",
    "processes = multiprocessing.cpu_count()\n",
    "objects = objaverse.load_objects(uids=[uid1,uid2],download_processes=processes)\n",
    "# from api\n",
    "model_1 = o3d.io.read_triangle_mesh(objects[uid1], True)\n",
    "model_2 = o3d.io.read_triangle_mesh(objects[uid2], True)\n",
    "#model_3 = o3d.io.read_triangle_mesh(objects[uid3], True)\n",
    "\n",
    "\n",
    "# from local\n",
    "#model_o3d = o3d.io.read_triangle_mesh(\"/mnt/project/AT3DCV_Data/source_models/deathwing.glb\", True)\n",
    "model_bounding_box1 = model_1.get_axis_aligned_bounding_box()\n",
    "model_bounding_box2 = model_2.get_axis_aligned_bounding_box()\n",
    "#model_bounding_box3 = model_3.get_axis_aligned_bounding_box()\n",
    "\n",
    "# scene related\n",
    "scene = 'scene0024_00'\n",
    "dataset_path = '/mnt/project/AT3DCV_Data/Preprocessed_OpenScene/data/scannet_3d'\n",
    "scene_path = f'train/{scene}_vh_clean_2.pth'\n",
    "_path = path.join(dataset_path, scene_path)    \n",
    "\n",
    "# load 3D scene\n",
    "scene_array, scene_colors, scene_annot = torch.load(_path)\n",
    "\n",
    "scene_o3d = o3d.geometry.PointCloud()\n",
    "scene_o3d.points = o3d.utility.Vector3dVector(scene_array)\n",
    "scene_o3d.colors = o3d.utility.Vector3dVector(scene_colors)\n",
    "\n",
    "scene_bounding_box = scene_o3d.get_oriented_bounding_box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5430b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the new object\n",
    "# scale_factor = 0.2 / -model_bounding_box.max_bound[2]\n",
    "\n",
    "# for birds\n",
    "scale_factor = 2\n",
    "model_1.scale(scale_factor+1, model_1.get_center())\n",
    "model_2.scale(scale_factor+2, model_2.get_center())\n",
    "#model_3.scale(scale_factor+5, model_3.get_center())\n",
    "model_bounding_box1.scale(scale_factor, np.zeros(3))\n",
    "model_bounding_box2.scale(scale_factor, np.zeros(3))\n",
    "#model_bounding_box3.scale(scale_factor, np.zeros(3))\n",
    "\n",
    "\n",
    "#for single objects (old code)\n",
    "#model_o3d.scale(scale_factor, model_o3d.get_center())\n",
    "#model_bounding_box.scale(scale_factor, np.zeros(3))\n",
    "\n",
    "#translate birds\n",
    "model_1.translate((4.795, 4.284, 1.12),relative=False)\n",
    "#model_1.translate((2.570, 1.894, 0.23),relative=False)\n",
    "#model_1.translate((3.290, 1.264, 0.56),relative=False)\n",
    "#model_2.translate((1.253, 6.613, 0.5),relative=False)\n",
    "model_2.translate((2.253, 5.613, 0.2),relative=False)\n",
    "#model_2.translate((4.323, 5.391, 0.84),relative=False)\n",
    "#model_3.translate((2.279,4.640,0.9),relative=False)\n",
    "\n",
    "#rotate birds\n",
    "model_1.rotate(model_1.get_rotation_matrix_from_xyz((np.pi /2, np.pi/1.5, 0 )), center=model_1.get_center())\n",
    "model_2.rotate(model_2.get_rotation_matrix_from_xyz((np.pi /2, np.pi/4, 0 )), center=model_2.get_center())\n",
    "#model_3.rotate(model_3.get_rotation_matrix_from_xyz((np.pi /2, np.pi/8, 0 )), center=model_3.get_center())\n",
    "\n",
    "#model_o3d.translate(scene_bounding_box.center,relative=False)\n",
    "#model_o3d.translate((0,-1,0))\n",
    "\n",
    "#model_o3d.rotate(model_o3d.get_rotation_matrix_from_xyz((np.pi /2, np.pi/8, 0 )), center=model_o3d.get_center())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d46704",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_plotly([scene_o3d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350c2b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "geometries = [model_1,model_2,scene_o3d]\n",
    "#geometries = [augmented_scene_o3d]\n",
    "viewer = o3d.visualization.Visualizer()\n",
    "viewer.create_window()\n",
    "for geometry in geometries:\n",
    "    viewer.add_geometry(geometry)\n",
    "opt = viewer.get_render_option()\n",
    "opt.show_coordinate_frame = True\n",
    "opt.background_color = np.asarray([0.5, 0.5, 0.5])\n",
    "viewer.run()\n",
    "viewer.destroy_window()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae98aaca",
   "metadata": {},
   "source": [
    "# exporting pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0bd8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_points(model, amount, voxel_size):\n",
    "    # sampling points from mesh\n",
    "    down_model = model.sample_points_uniformly(amount)\n",
    "    down_model = down_model.voxel_down_sample(voxel_size = voxel_size)\n",
    "\n",
    "    if np.asarray(down_model.colors).size == 0:\n",
    "        down_model.paint_uniform_color(np.array([0, 0, 0]))\n",
    "    return down_model\n",
    "\n",
    "def create_labels(model, label):\n",
    "    model_labels = np.full(np.asarray(model.points).shape[0], label)\n",
    "    print(f'labels created for total of {np.asarray(model.points).shape[0]} points')\n",
    "    return model_labels\n",
    "\n",
    "# if crop is necessary somehow\n",
    "def crop_point_cloud_by_z(point_cloud, z_threshold):\n",
    "    # Extract Z coordinates from point cloud\n",
    "    points = np.asarray(point_cloud.points)\n",
    "    z_values = points[:, 2]\n",
    "\n",
    "    # Find points with Z coordinates lower than the threshold\n",
    "    indices = np.where(z_values >= z_threshold)[0]\n",
    "\n",
    "    # Create a new point cloud with the cropped points\n",
    "    cropped_point_cloud = point_cloud.select_by_index(indices.tolist())\n",
    "\n",
    "    return cropped_point_cloud\n",
    "\n",
    "d_model_1 = sample_points(model_1, 3000, 0.015)\n",
    "d_model_2 = sample_points(model_2, 3000, 0.015)\n",
    "#d_model_3 = sample_points(model_3, 3000, 0.02)\n",
    "\n",
    "labels_1 = create_labels(d_model_1, 20.0)\n",
    "labels_2 = create_labels(d_model_2, 21.0)\n",
    "#labels_3 = create_labels(d_model_3, 22.0)\n",
    "\n",
    "# concatenating scene and object arrays\n",
    "augmented_scene_points = np.concatenate([np.asarray(scene_o3d.points), np.asarray(d_model_1.points), np.asarray(d_model_2.points)])\n",
    "augmented_scene_colors = np.concatenate([np.asarray(scene_o3d.colors), np.asarray(d_model_1.colors), np.asarray(d_model_2.colors)])\n",
    "augmented_scene_labels = np.concatenate([scene_annot, labels_1, labels_2])\n",
    "\n",
    "# saving as a torch file\n",
    "OUT_DIR_3D = \"/mnt/project/AT3DCV_Data/Preprocessed_OpenScene/data/augmented/birds_new/scannet_3d\"\n",
    "TAG = \"example\"\n",
    "\n",
    "torch.save((augmented_scene_points, augmented_scene_colors, augmented_scene_labels),\n",
    "           path.join(OUT_DIR_3D, TAG, scene_path.split('/')[-1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff10957b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just to visualize it in here\n",
    "augmented_scene_o3d = o3d.geometry.PointCloud()\n",
    "augmented_scene_o3d.points = o3d.utility.Vector3dVector(augmented_scene_points)\n",
    "augmented_scene_o3d.colors = o3d.utility.Vector3dVector(augmented_scene_colors)\n",
    "o3d.visualization.draw_geometries([augmented_scene_o3d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49847ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test if written file is correct\n",
    "aug_test = torch.load(path.join(OUT_DIR_3D, TAG, scene_path.split('/')[-1]))\n",
    "\n",
    "sample_points  = aug_test[0]\n",
    "sample_colors = aug_test[1]\n",
    "\n",
    "aug_test_pcd = o3d.geometry.PointCloud()\n",
    "aug_test_pcd.points = o3d.utility.Vector3dVector(np.asarray(sample_points))\n",
    "aug_test_pcd.colors = o3d.utility.Vector3dVector(np.asarray(sample_colors))\n",
    "\n",
    "o3d.visualization.draw_geometries([aug_test_pcd])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d979b6",
   "metadata": {},
   "source": [
    "# exporting .glb file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5a42e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to export transformed object as .obj o we can read it with read_triangle_model() for rendering\n",
    "o3d.io.write_triangle_mesh(\"/mnt/project/AT3DCV_Data/exported/NicobarPigeon_mesh.obj\", model_1)\n",
    "o3d.io.write_triangle_mesh(\"/mnt/project/AT3DCV_Data/exported/EasternRosella_mesh.obj\", model_2)\n",
    "#o3d.io.write_triangle_mesh(\"/mnt/project/AT3DCV_Data/exported/MousecoloredTyrannulet_mesh.obj\", model_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684d3317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to check if exported object is correct\n",
    "exported_mesh_1 = o3d.io.read_triangle_mesh(\"/mnt/project/AT3DCV_Data/exported/NicobarPigeon_mesh.obj\", True)\n",
    "exported_mesh_2 = o3d.io.read_triangle_mesh(\"/mnt/project/AT3DCV_Data/exported/EasternRosella_mesh.obj\", True)\n",
    "#exported_mesh_3 = o3d.io.read_triangle_mesh(\"/mnt/project/AT3DCV_Data/exported/MousecoloredTyrannulet_mesh.obj\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3c4676",
   "metadata": {},
   "outputs": [],
   "source": [
    "exported_mesh_1.textures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e500e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([exported_mesh_1,exported_mesh_2,scene_o3d])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902a7de4",
   "metadata": {},
   "source": [
    "# projecting back (test with a certain view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0932f37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://www.open3d.org/docs/latest/python_example/visualization/index.html#render-to-image-py\n",
    "\n",
    "scene = 'scene0024_00'\n",
    "scene_img = '2440'\n",
    "\n",
    "extrinsic_matrix = np.loadtxt(f'/mnt/project/AT3DCV_Data/Preprocessed_OpenScene/data/scannet_2d/{scene}/pose/{scene_img}.txt')\n",
    "    \n",
    "intrinsic_matrix = np.loadtxt(f'/mnt/project/AT3DCV_Data/Preprocessed_OpenScene/data/scannet_2d/intrinsics.txt')\n",
    "\n",
    "img_path = f'/mnt/project/AT3DCV_Data/Preprocessed_OpenScene/data/scannet_2d/{scene}/color/{scene_img}.jpg'\n",
    "depth_path = f'/mnt/project/AT3DCV_Data/Preprocessed_OpenScene/data/scannet_2d/{scene}/depth/{scene_img}.png'\n",
    "\n",
    "scannet_img = np.asarray(o3d.io.read_image(img_path))\n",
    "\n",
    "scannet_depth = np.asarray(o3d.io.read_image(depth_path))\n",
    "\n",
    "img_height, img_width = scannet_depth.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0a5a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "render = o3d.visualization.rendering.OffscreenRenderer(img_width, img_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd00f8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "render.scene.set_background([1, 1, 1, 0])\n",
    "render.scene.show_axes(True)\n",
    "\n",
    "#white = o3d.visualization.rendering.MaterialRecord()\n",
    "#white.base_color = [1.0, 1.0, 1.0, 1.0]\n",
    "#white.shader = \"defaultLit\"\n",
    "\n",
    "#material = o3d.visualization.rendering.MaterialRecord()\n",
    "#texture = np.asarray(model_o3d.textures).copy()\n",
    "#texture = o3d.geometry.Image(texture)\n",
    "#material.albedo_img = texture\n",
    "\n",
    "_object = o3d.io.read_triangle_model(\"/mnt/project/AT3DCV_Data/exported/EasternRosella_mesh.obj\")\n",
    "\n",
    "render.scene.add_model(\"model\", _object)\n",
    "\n",
    "vfov = 2 * np.arctan(img_height / (2 * intrinsic_matrix[1, 1]))\n",
    "eye = extrinsic_matrix[:3, 3]\n",
    "lookat = eye + (extrinsic_matrix[:3, :3] @ np.array([0, 0, 1]))\n",
    "up = (extrinsic_matrix[:3, :3] @ np.array([0, -1, 0]))\n",
    "\n",
    "render.setup_camera(vfov*180/np.pi, lookat, eye, up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a738c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_model = np.asarray(render.render_to_image())\n",
    "depth_model = np.asarray(render.render_to_depth_image(z_in_view_space=True)) * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c4818c",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_depth = np.asarray(scannet_depth).copy()\n",
    "aug_img = np.asarray(scannet_img).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087be142",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_depth_interp = aug_depth.copy()\n",
    "\n",
    "# very simple (but not smart) interpolation of missing depth values for masking of 3d model\n",
    "mask = (aug_depth==0)\n",
    "aug_depth_interp[mask] = np.interp(np.flatnonzero(mask), np.flatnonzero(~mask), aug_depth[~mask])\n",
    "\n",
    "#mask = np.all(np.array([aug_depth == 0, depth_model < np.inf]), axis=0)\n",
    "#mask = np.any(np.array([aug_depth > depth_model, mask]), axis=0)\n",
    "\n",
    "model_mask = aug_depth_interp > depth_model\n",
    "\n",
    "aug_depth[model_mask] = depth_model[model_mask]\n",
    "aug_img[model_mask] = img_model[model_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0ca881",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('augmented_2d.png', format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c297e69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(15, 15))\n",
    "ax[0].imshow(scannet_img)\n",
    "ax[1].imshow(scannet_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a93ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(15, 15))\n",
    "ax[0].imshow(aug_img)\n",
    "ax[1].imshow(aug_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcee322",
   "metadata": {},
   "source": [
    "# project back to all views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a118ef50",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_object_path_1 = \"/mnt/project/AT3DCV_Data/exported/NicobarPigeon_mesh.obj\"\n",
    "transformed_object_path_2 = \"/mnt/project/AT3DCV_Data/exported/EasternRosella_mesh.obj\"\n",
    "\n",
    "OUT_DIR_2D = \"/mnt/project/AT3DCV_Data/Preprocessed_OpenScene/data/augmented/birds_new/scannet_2d\"\n",
    "scene = 'scene0024_00'\n",
    "\n",
    "# read intrinsics \n",
    "intrinsic_matrix = np.loadtxt(f'/mnt/project/AT3DCV_Data/Preprocessed_OpenScene/data/scannet_2d/intrinsics.txt')\n",
    "# initialize paths\n",
    "aug_scene_folder = path.join(OUT_DIR_2D,scene)\n",
    "aug_color_path = path.join(aug_scene_folder, \"color\")\n",
    "aug_depth_path = path.join(aug_scene_folder, \"depth\")\n",
    "aug_pose_path  = path.join(aug_scene_folder, \"pose\")\n",
    "\n",
    "# create folders if not exists\n",
    "if not path.exists(aug_scene_folder):\n",
    "   os.makedirs(aug_scene_folder)\n",
    "if not path.exists(aug_color_path):\n",
    "   os.makedirs(aug_color_path)\n",
    "if not path.exists(aug_depth_path):\n",
    "   os.makedirs(aug_depth_path)\n",
    "if not path.exists(aug_pose_path):\n",
    "   os.makedirs(aug_pose_path)\n",
    "\n",
    "# original 2D data path\n",
    "original_path = f'/mnt/project/AT3DCV_Data/Preprocessed_OpenScene/data/scannet_2d/{scene}'\n",
    "\n",
    "# copy pose files if files does not match\n",
    "# ori_p_files = os.listdir(path.join(original_path,\"pose\"))\n",
    "# tgt_p_files = os.listdir(aug_pose_path)\n",
    "# if not tgt_p_files == ori_p_files: \n",
    "#   for fname in files: shutil.copy2(os.path.join(original_pose_path,fname), aug_pose_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5661e6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of images ids\n",
    "image_ids = [_id.split(\".\")[0] for _id in os.listdir(path.join(original_path,\"color\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dedd5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read only one to extract the size of the image so we create renderer only once at the beginning\n",
    "ex_img = f'/mnt/project/AT3DCV_Data/Preprocessed_OpenScene/data/scannet_2d/{scene}/depth/{image_ids[0]}.png'\n",
    "_h, _w= np.asarray(o3d.io.read_image(ex_img)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c22eaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create renderer\n",
    "render = o3d.visualization.rendering.OffscreenRenderer(_w, _h)\n",
    "render.scene.set_background([1, 1, 1, 0])\n",
    "render.scene.show_axes(True)\n",
    "_object1 = o3d.io.read_triangle_model(transformed_object_path_1)\n",
    "render.scene.add_model(\"object1\", _object1)\n",
    "_object2 = o3d.io.read_triangle_model(transformed_object_path_2)\n",
    "render.scene.add_model(\"object2\", _object2)\n",
    "\n",
    "render.scene.scene.set_sun_light(\n",
    "            [1, 1, 1],  # direction\n",
    "            [1, 1, 1],  # color\n",
    "            100000)  # intensity\n",
    "render.scene.scene.enable_sun_light(True)\n",
    "\n",
    "#_object3 = o3d.io.read_triangle_model(transformed_object_path_3)\n",
    "#render.scene.add_model(\"object3\", _object3)\n",
    "\n",
    "# vertical fov\n",
    "vfov = 2 * np.arctan(_h / (2 * intrinsic_matrix[1, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68064e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over each image\n",
    "_compact = \"/mnt/project/AT3DCV_Data/Preprocessed_OpenScene/data/scannet_2d/\"\n",
    "for _id in tqdm(image_ids):\n",
    "    extrinsic_matrix = np.loadtxt(f'{_compact}{scene}/pose/{_id}.txt')\n",
    "    _img = np.asarray(o3d.io.read_image(f'{_compact}{scene}/color/{_id}.jpg'))\n",
    "    _depth = np.asarray(o3d.io.read_image(f'{_compact}{scene}/depth/{_id}.png'))\n",
    "        \n",
    "    #necessary calculations for each image\n",
    "    eye = extrinsic_matrix[:3, 3]\n",
    "    lookat = eye + (extrinsic_matrix[:3, :3] @ np.array([0, 0, 1]))\n",
    "    up = (extrinsic_matrix[:3, :3] @ np.array([0, -1, 0]))\n",
    "    \n",
    "    # change camera position\n",
    "    render.setup_camera(vfov*180/np.pi, lookat, eye, up)\n",
    "    \n",
    "    img_model = np.asarray(render.render_to_image())\n",
    "    depth_model = np.asarray(render.render_to_depth_image(z_in_view_space=True)) * 1000\n",
    "    \n",
    "    aug_depth = np.asarray(_depth).copy()\n",
    "    aug_img = np.asarray(_img).copy()\n",
    "\n",
    "    aug_depth_interp = aug_depth.copy()\n",
    "\n",
    "    # very simple (but not smart) interpolation of missing depth values for masking of 3d model\n",
    "    mask = (aug_depth==0)\n",
    "    aug_depth_interp[mask] = np.interp(np.flatnonzero(mask), np.flatnonzero(~mask), aug_depth[~mask])\n",
    "\n",
    "    #mask = np.all(np.array([aug_depth == 0, depth_model < np.inf]), axis=0)\n",
    "    #mask = np.any(np.array([aug_depth > depth_model, mask]), axis=0)\n",
    "\n",
    "    model_mask = aug_depth_interp > depth_model\n",
    "\n",
    "    aug_depth[model_mask] = depth_model[model_mask]\n",
    "    aug_img[model_mask] = img_model[model_mask]\n",
    "    \n",
    "    o3d.io.write_image(path.join(aug_color_path, f'{_id}.jpg'), o3d.geometry.Image(aug_img))\n",
    "    o3d.io.write_image(path.join(aug_depth_path,f'{_id}.png'), o3d.geometry.Image(aug_depth))\n",
    "\n",
    "    tqdm.write(f'{_id} is written', end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdb74b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# legacy\n",
    "\n",
    "#diamond firetail 12 cm\n",
    "uid1 =\"f30e9661f2de4c9eb14bfe1bd8bf15e0\"\n",
    "# Blue-faced Honeyeater  29.5 cm\n",
    "uid2 = \"f1cb8473b258433ab9bb61f8a96b4867\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
