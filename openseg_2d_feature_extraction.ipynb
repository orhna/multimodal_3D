{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dcaa42da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import imageio\n",
    "import argparse\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from tqdm import tqdm, trange\n",
    "import tensorflow as tf2\n",
    "import tensorflow.compat.v1 as tf\n",
    "from tensorflow import io\n",
    "from os.path import join, exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb8ba2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_bytes(path):\n",
    "    '''Read bytes for OpenSeg model running.'''\n",
    "\n",
    "    with io.gfile.GFile(path, 'rb') as f:\n",
    "        file_bytes = f.read()\n",
    "    return file_bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbe276e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load openseg model\n",
    "openseg_model = tf2.saved_model.load(\"C:/Users/aorhu/Masaüstü/AT3DCV/repo/openseg_model\",tags=[tf.saved_model.tag_constants.SERVING],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efcb8173",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 'train'\n",
    "n_split_points = 20000\n",
    "num_rand_file_per_scene = 5\n",
    "\n",
    "\n",
    "data_dir = \"D:/AT3DCV_Data/Preprocessed_OpenScene/data\"\n",
    "data_root = join(data_dir, 'scannet_3d')\n",
    "data_root_2d = join(data_dir,'scannet_2d')\n",
    "\n",
    "data_paths = sorted(glob(join(data_root, split, '*.pth')))\n",
    "\n",
    "out_dir = \"D:/AT3DCV_Data/Preprocessed_OpenScene/data/features_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "070447c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:/AT3DCV_Data/Preprocessed_OpenScene/data\\\\scannet_3d\\\\train\\\\scene0000_00_vh_clean_2.pth'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b972752f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_id = data_paths[0].split('/')[-1].split('\\\\')[-1].split('_vh')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "846a3da6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'scene0000_00'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scene_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2a53af9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = join(data_root_2d, scene_id)\n",
    "img_dirs = sorted(glob(join(scene, 'color/*')), key=lambda x: int(os.path.basename(x)[:-4]))\n",
    "num_img = len(img_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "34431613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:/AT3DCV_Data/Preprocessed_OpenScene/data\\\\scannet_2d\\\\scene0000_00\\\\color\\\\0.jpg'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_dirs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9fd7f4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_emb = tf.zeros([1, 1, 768])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "209dc139",
   "metadata": {},
   "outputs": [],
   "source": [
    "regional_pool = True #by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aa714d3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/279 [00:05<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "img_features = []\n",
    "for img_dir in tqdm(img_dirs):\n",
    "    np_image_string = read_bytes(img_dir)\n",
    "    results = openseg_model.signatures['serving_default'](\n",
    "                inp_image_bytes = tf.convert_to_tensor(np_image_string),\n",
    "                inp_text_emb = text_emb)\n",
    "    \n",
    "    img_info = results['image_info']\n",
    "    crop_sz = [int(img_info[0, 0] * img_info[2, 0]), int(img_info[0, 1] * img_info[2, 1])]\n",
    "    \n",
    "    if regional_pool:\n",
    "        image_embedding_feat = results['ppixel_ave_feat'][:, :crop_sz[0], :crop_sz[1]]\n",
    "    else:\n",
    "        image_embedding_feat = results['image_embedding_feat'][:, :crop_sz[0], :crop_sz[1]]\n",
    "\n",
    "    feat_2d = tf.cast(tf.image.resize_nearest_neighbor(\n",
    "            image_embedding_feat, [240,320], align_corners=True)[0], dtype=tf.float16).numpy()\n",
    "    feat_2d = torch.from_numpy(feat_2d).permute(2, 0, 1)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8ea30611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['region_probs_', 'text_embedding', 'segm_proposal_feats', 'image_embedding_feat', 'pixel_pred_confidence', 'segm_confidence', 'segm_prediction', 'images', 'region_embeddings', 'region_probs', 'ppixel_ave_feat', 'ppixel_ave_feat_confidence', 'segm_confidence_rw', 'image', 'segm_prediction_rw', 'image_info', 'ppixel_ave_feat_pred', 'pixel_prediction', 'segm_proposal', 'region_logits'])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01360e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_embedding_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eaea3730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768, 240, 320])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_2d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9dce154b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 3.0078e-01,  2.4695e-01,  2.4695e-01,  ...,  2.5781e-01,\n",
       "           2.5781e-01,  2.5781e-01],\n",
       "         [ 1.6809e-01,  2.2083e-01,  2.2083e-01,  ...,  2.5781e-01,\n",
       "           2.5781e-01,  2.5781e-01],\n",
       "         [ 1.4209e-01,  9.3323e-02,  1.7212e-01,  ...,  2.5781e-01,\n",
       "           2.5781e-01,  2.5781e-01],\n",
       "         ...,\n",
       "         [ 9.4666e-02,  5.4077e-02,  5.4077e-02,  ...,  3.4973e-02,\n",
       "           3.4973e-02,  3.4973e-02],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[ 2.9980e-01,  1.9580e-01,  1.9580e-01,  ...,  1.4075e-01,\n",
       "           1.4075e-01,  1.4075e-01],\n",
       "         [ 1.4307e-01,  1.4001e-01,  1.4001e-01,  ...,  1.4075e-01,\n",
       "           1.4075e-01,  1.4075e-01],\n",
       "         [ 8.7158e-02,  7.1838e-02,  1.2469e-01,  ...,  1.4075e-01,\n",
       "           1.4075e-01,  1.4075e-01],\n",
       "         ...,\n",
       "         [ 8.6121e-02,  4.5441e-02,  4.5441e-02,  ...,  6.6519e-04,\n",
       "           6.6519e-04,  6.6519e-04],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[-1.9031e-01, -1.3733e-01, -1.3733e-01,  ..., -1.2306e-02,\n",
       "          -1.2306e-02, -1.2306e-02],\n",
       "         [-1.2646e-01, -1.0498e-01, -1.0498e-01,  ..., -1.2306e-02,\n",
       "          -1.2306e-02, -1.2306e-02],\n",
       "         [-9.4055e-02, -5.8777e-02, -6.9702e-02,  ..., -1.2306e-02,\n",
       "          -1.2306e-02, -1.2306e-02],\n",
       "         ...,\n",
       "         [-1.9821e-02, -2.6657e-02, -2.6657e-02,  ..., -1.5282e-02,\n",
       "          -1.5282e-02, -1.5282e-02],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 3.1006e-02,  3.7292e-02,  3.7292e-02,  ...,  1.4793e-02,\n",
       "           1.4793e-02,  1.4793e-02],\n",
       "         [ 4.6387e-02,  3.8483e-02,  3.8483e-02,  ...,  1.4793e-02,\n",
       "           1.4793e-02,  1.4793e-02],\n",
       "         [ 4.7546e-02,  2.5085e-02,  1.6006e-02,  ...,  1.4793e-02,\n",
       "           1.4793e-02,  1.4793e-02],\n",
       "         ...,\n",
       "         [ 1.8167e-04,  6.1836e-03,  6.1836e-03,  ...,  1.6556e-02,\n",
       "           1.6556e-02,  1.6556e-02],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[-1.6687e-01, -1.2512e-01, -1.2512e-01,  ..., -7.1777e-02,\n",
       "          -7.1777e-02, -7.1777e-02],\n",
       "         [-1.0388e-01, -1.0699e-01, -1.0699e-01,  ..., -7.1777e-02,\n",
       "          -7.1777e-02, -7.1777e-02],\n",
       "         [-8.5693e-02, -9.0332e-02, -1.1157e-01,  ..., -7.1777e-02,\n",
       "          -7.1777e-02, -7.1777e-02],\n",
       "         ...,\n",
       "         [ 3.1708e-02,  2.9510e-02,  2.9510e-02,  ...,  1.4404e-02,\n",
       "           1.4404e-02,  1.4404e-02],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[-1.1169e-01, -8.6670e-02, -8.6670e-02,  ...,  8.9355e-02,\n",
       "           8.9355e-02,  8.9355e-02],\n",
       "         [-1.1926e-01, -8.3374e-02, -8.3374e-02,  ...,  8.9355e-02,\n",
       "           8.9355e-02,  8.9355e-02],\n",
       "         [-1.1597e-01, -3.9124e-02, -6.5269e-03,  ...,  8.9355e-02,\n",
       "           8.9355e-02,  8.9355e-02],\n",
       "         ...,\n",
       "         [-2.0657e-03,  1.3123e-02,  1.3123e-02,  ..., -7.2571e-02,\n",
       "          -7.2571e-02, -7.2571e-02],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00]]], dtype=torch.float16)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3366d8e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
