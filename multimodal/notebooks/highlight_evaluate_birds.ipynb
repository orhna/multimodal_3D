{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37317be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from tqdm.notebook import tqdm\n",
    "from os.path import join, exists\n",
    "import open3d as o3d\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import combinations\n",
    "import copy\n",
    "from tabulate import tabulate\n",
    "import clip\n",
    "\n",
    "model, _ = clip.load(\"ViT-L/14@336px\")\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e329a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbaa988c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all the required data\n",
    "source_path = \"/mnt/project/AT3DCV_Data/Preprocessed_OpenScene/data/augmented/birds_new/scannet_3d/example/scene0024_00_vh_clean_2.pth\"\n",
    "fused_path = \"/mnt/project/AT3DCV_Data/Preprocessed_OpenScene/data/augmented/birds_new/fused/scene0024_00_0.pt\"\n",
    "distilled_path = \"/mnt/project/AT3DCV_Data/Preprocessed_OpenScene/data/augmented/birds_new/features_3D/scene0024_00_vh_clean_2_openscene_feat_distill.npy\"\n",
    "\n",
    "source_points, source_colors, source_labels = load_scene(source_path, False)\n",
    "\n",
    "fused_f, filtered_pc, filtered_pc_c, filtered_pc_labels, indices = load_fused_features(fused_path,\n",
    "                                                                              source_points, \n",
    "                                                                              source_colors,\n",
    "                                                                              source_labels)\n",
    "distilled_f = load_distilled_features(distilled_path, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff506b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# info about scene with birds\n",
    "# Nicobar Pigeon          class label = 20, 1797 points, on the table\n",
    "# Eastern Rosella          class label = 21, 1787 points, on the stairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b12ea0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query\n",
    "#query = [\"a bird which is grey-breasted\", \"a bird which is brown-crowned\", \"a bird which is yellow-eyed\"]\n",
    "#query = [\"a bird\"]\n",
    "#query = [\"Eastern Rosella bird in a scene\"]\n",
    "query = [\"nicobar pigeon bird in a scene\"]\n",
    "#query = [\"a bird which has Slender-bodied.\", 'a bird which has Long-tail.',\n",
    "#                                  'a bird which has White-barred-wings.','a bird which has Red-legs.',\n",
    "#                                  'a bird which has Grey-breast.']\n",
    "        \n",
    "query = ['a bird which has White-tipped wings.',\n",
    " 'a bird which has Yellow belly.',\n",
    " 'a bird which has Orange cheeks.',\n",
    " 'a bird which has Broad wings.',\n",
    " 'a bird which has White eye-ring..']\n",
    "        \n",
    "query = [\"a bird\"]    \n",
    "        \n",
    "similarity = highlight_query(query, \"fused\", \"max\", distilled_f, fused_f, filtered_pc, filtered_pc_c, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b70fa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually set descriptors if necessary\n",
    "descriptors = {\"Eastern Rosella\": ['a bird which is/has Orange-breast.',\n",
    "  'a bird which is/has Blue-tail.',\n",
    "  'a bird which is/has White-cheek.',\n",
    "  'a bird which is/has Black-eye-ring.',\n",
    "  'a bird which is/has Yellow-wing-bar.'],\n",
    "               \"nicobar pigeon\" : ['a bird which is/has Purple-neck.',\n",
    "  'a bird which is/has Red-breast.',\n",
    "  'a bird which is/has Long-tail.',\n",
    "  'a bird which is/has Black-beak.',\n",
    "  'a bird which is/has Gray-crown.']\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fd9c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCANNET_LABELS_20 = ['wall', 'floor', 'cabinet', 'bed', 'chair', 'sofa',\n",
    "                     'table', 'door', 'window', 'bookshelf', 'picture','counter', 'desk', 'curtain', 'refrigerator', 'shower curtain',\n",
    "                     'toilet', 'sink', 'bathtub', 'otherfurniture']\n",
    "UNKNOWN_ID = 255\n",
    "NO_FEATURE_ID = 256\n",
    "\n",
    "for key, value in descriptors.items():\n",
    "    SCANNET_LABELS_20.append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c23d503",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCANNET_LABELS_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e308209a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04f541c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_ious, class_accs, mean_iou, mean_acc, pred_ids = evaluate(SCANNET_LABELS_20, descriptors, model, \"fused\", \"max\" , distilled_f, fused_f, filtered_pc_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7918e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_ious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d710be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all the added object labels into 20 \n",
    "# gt_ids = np.where(np.logical_or(filtered_pc_labels == 21, filtered_pc_labels == 22), 20, filtered_pc_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6017598",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc957265",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_results_table(SCANNET_LABELS_20, class_ious, descriptors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84208e29",
   "metadata": {},
   "source": [
    "# experiment with different descriptor combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0978ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import clip\n",
    "model, _ = clip.load(\"ViT-L/14@336px\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1e72d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parse descriptors from openai api with gpt, set _nr to the number of descriptors you'd want to retrieve\n",
    "_nr = 10\n",
    "_prompt = f'Generate {str(_nr)} visual descriptors for each of the following categories, they are bird species: [Nicobar Pigeon, Eastern Rosella]. The descriptors will be used for input queries for a CLIP model. The descriptors should be concise and distinct from the descriptors of the other classes. Do not focus on behavior, but purely on attributes which are recognizable by the CLIP model. The output should be in the following form as a string: *bird name*: *descriptor1*, *descriptor2*, etc.\"'\n",
    "descriptors = descriptors_from_prompt(_prompt, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43485d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptors = {'Nicobar Pigeon': ['a bird which is/has Green-blue plumage.',\n",
    "  'a bird which is/has Metallic-sheen feathers.',\n",
    "  'a bird which is/has Slender body.',\n",
    "  'a bird which is/has Long tail feathers.',\n",
    "  'a bird which is/has Light brown head.',\n",
    "  'a bird which is/has Red beak.',\n",
    "  'a bird which is/has White eye-ring.',\n",
    "  'a bird which is/has Pink feet.',\n",
    "  'a bird which is/has Dark neck patch.',\n",
    "  'a bird which is/has Yellow shoulder stripe..'],\n",
    " 'Eastern Rosella': ['a bird which is/has Red head.',\n",
    "  'a bird which is/has Red shoulder patches.',\n",
    "  'a bird which is/has Blue wings.',\n",
    "  'a bird which is/has White breast.',\n",
    "  'a bird which is/has Yellow belly.',\n",
    "  'a bird which is/has Orange-red tail.',\n",
    "  'a bird which is/has Black beak.',\n",
    "  'a bird which is/has Blue-green back.',\n",
    "  'a bird which is/has White eye-ring.',\n",
    "  'a bird which is/has Long tail feathers..']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6ca0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCANNET_LABELS_20 = ['wall', 'floor', 'cabinet', 'bed', 'chair', 'sofa',\n",
    "                     'table', 'door', 'window', 'bookshelf', 'picture','counter', 'desk', 'curtain', 'refrigerator', 'shower curtain',\n",
    "                     'toilet', 'sink', 'bathtub', 'otherfurniture']\n",
    "UNKNOWN_ID = 255\n",
    "NO_FEATURE_ID = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bd76fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to test without descriptors\n",
    "comb_dict_list =[ {\n",
    "  }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cb1da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get combinations of 5 out of *_nr* descriptors for each class\n",
    "comb_dict_list = combinations_descriptor(descriptors, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f98d99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_dict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6927a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_pc_labels[np.where(filtered_pc_labels == 21)] = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e64f69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(filtered_pc_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1027f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate all the combinations and store their results in a list\n",
    "class_IoU_result_list, class_accs_result_list, mean_iou_result_list, mean_acc_result_list, pred_ids_list = try_diff_combs(SCANNET_LABELS_20, comb_dict_list, model, \"fused\", \"max\", distilled_f, fused_f, filtered_pc_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abef6f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0th index of the list corresponds to the descriptors that belongs to the 0th index of the comb_dict_list\n",
    "class_IoU_result_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96924aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1, c2= [], [] # Nicobar Pigeon, Easter Rosella\n",
    "# store tp/ (tp + fp + fn) values in list per augmented class\n",
    "for idx in range(len(class_IoU_result_list)):\n",
    "    c1.append(class_IoU_result_list[idx][\"Nicobar Pigeon\"][0])\n",
    "    c2.append(class_IoU_result_list[idx][\"Eastern Rosella\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16f9af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_dict_list[c1.index(max(c1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7e18b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "max(c1), max(c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a735b6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "c2[c1.index(max(c1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84eec7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these 5 descriptors gives the highest class IoU for Easter Rosella\n",
    "comb_dict_list[c2.index(max(c2))]['Eastern Rosella']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c44ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these 5 descriptors gives the highest class IoU for Mouse-colored Tyrannulet\n",
    "comb_dict_list[c1.index(max(c1))]['Nicobar Pigeon']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d580434d",
   "metadata": {},
   "source": [
    "# visualization, birds as single category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb3ea6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels = pred_ids_list[c1.index(max(c1))].numpy()\n",
    "other_color = np.array([0.773, 0.922, 0.651])\n",
    "color_gt = np.tile(other_color, (len(filtered_pc_labels), 1))\n",
    "color_pred = np.tile(other_color, (len(filtered_pc_labels), 1))\n",
    "color_gt[np.where(filtered_pc_labels == 20)] = [1, 0.294, 0.165] # nicobar pigeon :red\n",
    "color_pred[np.where(pred_labels == 20)] = [1, 0.294, 0.165] # nicobar pigeon :red\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(filtered_pc)\n",
    "pcd.colors = o3d.utility.Vector3dVector(color_array)\n",
    "\n",
    "pcd_pred = o3d.geometry.PointCloud()\n",
    "pcd_pred.points = o3d.utility.Vector3dVector(np.asarray(filtered_pc) + [0,10,0])\n",
    "pcd_pred.colors = o3d.utility.Vector3dVector(color_pred)\n",
    "\n",
    "# Visualize the point cloud\n",
    "o3d.visualization.draw_geometries([pcd,pcd_pred])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735f82ae",
   "metadata": {},
   "source": [
    "# visualization by color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49628495",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels = pred_ids_list[c1.index(max(c1))].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfa2253",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels_bad = pred_ids_list[c1.index(max(c1))].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d73de46",
   "metadata": {},
   "outputs": [],
   "source": [
    "other_color = np.array([0.773, 0.922, 0.651])\n",
    "color_gt = np.tile(other_color, (len(filtered_pc_labels), 1))\n",
    "color_pred = np.tile(other_color, (len(filtered_pc_labels), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3b05c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_gt[np.where(filtered_pc_labels == 20)] = [1, 0.294, 0.165] # nicobar pigeon :red\n",
    "color_gt[np.where(filtered_pc_labels == 21)] = [0.024, 0.788, 1] # eastern rosella  :blue \n",
    "\n",
    "color_pred[np.where(pred_labels == 20)] = [1, 0.294, 0.165] # nicobar pigeon :red\n",
    "color_pred[np.where(pred_labels == 21)] = [0.024, 0.788, 1] # eastern rosella  :blue \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba176c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an Open3D point cloud\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(filtered_pc)\n",
    "pcd.colors = o3d.utility.Vector3dVector(color_array)\n",
    "\n",
    "pcd_pred = o3d.geometry.PointCloud()\n",
    "pcd_pred.points = o3d.utility.Vector3dVector(np.asarray(filtered_pc) + [0,10,0])\n",
    "pcd_pred.colors = o3d.utility.Vector3dVector(color_pred)\n",
    "\n",
    "# Visualize the point cloud\n",
    "o3d.visualization.draw_geometries([pcd,pcd_pred])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5c7f4c",
   "metadata": {},
   "source": [
    "# experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c461b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa64148",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for mean aggregation\n",
    "\n",
    "# max scores for Nicobar Pigeon\n",
    "_np = [0.3961, 0.6884, 0.5992, 0.6133, 0.5813, 0.5519, 0.5377, 0.5163, 0.5050, 0.4872, 0.4593]\n",
    "\n",
    "# max scores for Eastern Rosella\n",
    "_er = [0.0, 0.6626, 0.7036, 0.7115, 0.7289, 0.7233, 0.7122, 0.7138, 0.7006, 0.6887, 0.6778]\n",
    "\n",
    "_numbers = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb5b184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for max aggregation\n",
    "\n",
    "# max scores for Nicobar Pigeon\n",
    "_np = [0.3961, 0.6884, 0.7332, 0.7332, 0.7332, 0.7332, 0.7327, 0.7061, 0.6391, 0.4610, 0.1698]\n",
    "\n",
    "# max scores for Eastern Rosella\n",
    "_er = [0.0, 0.6626, 0.6815, 0.7330, 0.7346, 0.7346, 0.7321, 0.6792, 0.6790, 0.5396, 0.4600]\n",
    "\n",
    "\n",
    "_numbers = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f075f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=_numbers, y=_np, mode='lines+markers', name='Nicobar Pigeon',  line=dict(width=6)))\n",
    "fig.add_trace(go.Scatter(x=_numbers, y=_er, mode='lines+markers', name='Eastern Rosella', line=dict(width=6)))\n",
    "\n",
    "fig.update_layout(title='Effect of Descriptors,  Aggregation : max',\n",
    "                  xaxis_title='# of descriptors',\n",
    "                  yaxis_title='max mIoU scores',\n",
    "                  showlegend=True,\n",
    "                  plot_bgcolor='rgba(250,250, 250,1)', \n",
    "                  font=dict(\n",
    "                      family='Arial',  # Set the font family\n",
    "                      size=26,         # Set the font size\n",
    "                      color='black'    # Set the font color\n",
    "                  )\n",
    "                  )\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6cad80",
   "metadata": {},
   "outputs": [],
   "source": [
    "pio.write_image(fig, 'max agg.png', format='png', width=1200, height=1080, scale=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0089e1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883710f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bar chart for different prompts\n",
    "x_labels = ['a bird', 'Nicobar Pigeon', 'a Nicobar Pigeon bird', 'a Nicobar Pigeon bird in a scene']\n",
    "y_values = [0.2993, 0.4, 0.3856, 0.4141]\n",
    "\n",
    "#x_labels = ['a bird', 'Eastern Rosella', 'a Nicobar Pigeon bird', 'a Nicobar Pigeon bird in a scene']\n",
    "#y_values = [0.2993, 0.0, 0.3856, 0.4141]\n",
    "\n",
    "# Create a bar graph using the go.Bar function\n",
    "bar_graph = go.Bar(\n",
    "    x=x_labels,  # x-axis labels\n",
    "    y=y_values   # y-axis values\n",
    ")\n",
    "\n",
    "# Define the layout settings (optional)\n",
    "layout = go.Layout(\n",
    "    title='Different Prompts',\n",
    "    xaxis=dict(\n",
    "        title='Prompts',          # x-axis label\n",
    "        tickmode='array',            # Set tickmode to 'array' for custom tick labels\n",
    "        tickvals=list(range(len(x_labels))),  # Set tick positions           # Set tick labels\n",
    "        tickangle=0,                 # Rotate labels to 0 degrees (horizontal)\n",
    "        automargin=True,\n",
    "        # Automatically adjust margins to fit labels\n",
    "        tickfont=dict(size=30),  \n",
    "        ticktext=[\"<br>\".join(textwrap.wrap(label, width=12)) for label in x_labels]# Set font size for tick labels\n",
    "    ),  # x-axis label\n",
    "    yaxis=dict(title='mIoU'),\n",
    "    plot_bgcolor='rgba(250,250, 250,1)',\n",
    "    font=dict(family='Arial',  \n",
    "            size=26,         \n",
    "            color='black'),\n",
    "   # y-axis label\n",
    ")\n",
    "\n",
    "# Create the figure and add the bar graph to it\n",
    "fig = go.Figure(data=[bar_graph], layout=layout)\n",
    "fig.update_traces(\n",
    "    marker=dict(line=dict(width=1), color='green'),  # Set the border width of the bars\n",
    "    width=0.2                        # Set the width of the bars (0.4 means 40% of the available space)\n",
    ")\n",
    "# Add a horizontal line on the maximum y value\n",
    "\n",
    "max_y_value = max(y_values)\n",
    "fig.add_shape(\n",
    "    type='line',\n",
    "    x0=-0.5,   # Starting x position (corresponding to the first bar)\n",
    "    x1=len(x_labels) - 0.5,  # Ending x position (corresponding to the last bar)\n",
    "    y0=max_y_value,  # y position of the horizontal line (maximum y value)\n",
    "    y1=max_y_value,  # y position of the horizontal line (maximum y value)\n",
    "    line=dict(color='red', width=2),  # Line properties (color and width)\n",
    ")\n",
    "fig.update_layout(\n",
    "    uniformtext_minsize=8,  # Set the minimum size of text to avoid overlapping\n",
    "    uniformtext_mode='hide' # Hide text when it does not fit\n",
    ")\n",
    "# Display the graph\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef51a3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pio.write_image(fig, 'prompts.png', format='png', width=1220, height=1080, scale=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62305a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tested descriptors for different number of descriptors\n",
    "{'Nicobar Pigeon': ['a bird which is/has Green-blue plumage.',\n",
    "  'a bird which is/has Metallic-sheen feathers.',\n",
    "  'a bird which is/has Slender body.',\n",
    "  'a bird which is/has Long tail feathers.',\n",
    "  'a bird which is/has Light brown head.',\n",
    "  'a bird which is/has Red beak.',\n",
    "  'a bird which is/has White eye-ring.',\n",
    "  'a bird which is/has Pink feet.',\n",
    "  'a bird which is/has Dark neck patch.',\n",
    "  'a bird which is/has Yellow shoulder stripe..'],\n",
    " 'Eastern Rosella': ['a bird which is/has Red head.',\n",
    "  'a bird which is/has Red shoulder patches.',\n",
    "  'a bird which is/has Blue wings.',\n",
    "  'a bird which is/has White breast.',\n",
    "  'a bird which is/has Yellow belly.',\n",
    "  'a bird which is/has Orange-red tail.',\n",
    "  'a bird which is/has Black beak.',\n",
    "  'a bird which is/has Blue-green back.',\n",
    "  'a bird which is/has White eye-ring.',\n",
    "  'a bird which is/has Long tail feathers..']}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e75e97f",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14cb79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# should be the preprocessed file path\n",
    "sample_path_0 = \"/mnt/project/AT3DCV_Data/Preprocessed_OpenScene/data/augmented/birds/scannet_3d/example/scene0000_00_vh_clean_2.pth\"\n",
    "#sample_path_1 = \"D:/AT3DCV_Data/Preprocessed_OpenScene/data/scannet_3d/train/scene0000_01_vh_clean_2.pth\"\n",
    "#sample_path_2 = \"D:/AT3DCV_Data/Preprocessed_OpenScene/data/scannet_3d/train/scene0000_02_vh_clean_2.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de5eb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_0 = torch.load(sample_path_0) # coords,colors,labels\n",
    "#sample_1 = torch.load(sample_path_1) # coords,colors,labels\n",
    "#sample_2 = torch.load(sample_path_2) # coords,colors,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d69828",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sample_0[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d643bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregating all of the partial point clouds of the same scene (they don't overlap perfectly)\n",
    "#sample_points = np.concatenate((sample_0[0], sample_1[0], sample_2[0]))\n",
    "#sample_colors = np.concatenate((sample_0[1], sample_1[1], sample_2[1]))\n",
    "\n",
    "# single partial point cloud\n",
    "sample_points  = sample_0[0]\n",
    "sample_colors = sample_0[1]\n",
    "sample_labels = sample_0[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6663b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to view original scene\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(np.asarray(sample_points))\n",
    "#original colors\n",
    "pcd.colors = o3d.utility.Vector3dVector(np.asarray(sample_colors))\n",
    "#------\n",
    "#paint uniform\n",
    "#sample_paint_uniform = np.asarray([200,200,200])/255.0 #redish\n",
    "#pcd.paint_uniform_color(sample_paint_uniform)\n",
    "o3d.visualization.draw_geometries([pcd])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5135af0",
   "metadata": {},
   "source": [
    "# load fused features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212cf156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# should be the fused feature path\n",
    "feature_path = \"/mnt/project/AT3DCV_Data/Preprocessed_OpenScene/data/augmented/birds/fused/scene0000_00_0.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7f5bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = torch.load(feature_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12fcc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature[\"mask_full\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f474ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature[\"feat\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fc2d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the indices where the mask is True\n",
    "indices = torch.nonzero(feature[\"mask_full\"]).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65077247",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_point_cloud = sample_points[indices, :]\n",
    "filtered_point_cloud_colors = sample_colors[indices, :]\n",
    "filtered_point_cloud_labels = sample_labels[indices]\n",
    "gt_ids = filtered_point_cloud_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d360ff5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(filtered_point_cloud_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafeeff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace every occurrence of 21 with 20 if necessary\n",
    "gt_ids= np.where(filtered_point_cloud_labels == 21.0, 20.0, filtered_point_cloud_labels)\n",
    "gt_ids= np.where(gt_ids == 22.0, 20.0, gt_ids)\n",
    "# gt_ids = filtered_point_cloud_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee71e533",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(gt_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d482d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values, counts = np.unique(gt_ids, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5c60c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49eb65e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5798734e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_point_cloud.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afd5dbb",
   "metadata": {},
   "source": [
    "# using clip model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a01ad33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import clip\n",
    "model, preprocess = clip.load(\"ViT-L/14@336px\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56a8260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# highlight with a threshold\n",
    "# type the query here \n",
    "query = [\"dragon\"]\n",
    "\n",
    "with torch.no_grad():\n",
    "    all_text_embeddings = []\n",
    "    for category in tqdm(query):\n",
    "        texts = clip.tokenize(category)  #tokenize\n",
    "        texts = texts.cuda()\n",
    "        text_embeddings = model.encode_text(texts)  #embed with text encoder\n",
    "        text_embeddings /= text_embeddings.norm(dim=-1, keepdim=True)\n",
    "        text_embedding = text_embeddings.mean(dim=0)\n",
    "        text_embedding /= text_embedding.norm()\n",
    "        all_text_embeddings.append(text_embedding)\n",
    "\n",
    "    all_text_embeddings = torch.stack(all_text_embeddings, dim=1)\n",
    "\n",
    "# normalizing \n",
    "fused_f = (feature[\"feat\"]/(feature[\"feat\"].norm(dim=-1, keepdim=True)+1e-5)).half()\n",
    "# calculating similarity matrix\n",
    "# similarity_matrix = torch.matmul(feature[\"feat\"].cuda(), all_text_embeddings) # \n",
    "similarity_matrix = fused_f.cuda() @ all_text_embeddings    \n",
    "    \n",
    "# set higher to increase the certainty (not always correct)\n",
    "threshold_percentage = 0.9\n",
    "cap = similarity_matrix.max().item()\n",
    "found_indices = torch.nonzero(similarity_matrix > cap*threshold_percentage, as_tuple=False).squeeze().T[0]\n",
    "\n",
    "# creating pc\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(np.asarray(filtered_point_cloud))\n",
    "pcd.colors = o3d.utility.Vector3dVector(np.asarray(filtered_point_cloud_colors))\n",
    "\n",
    "found_region = pcd.select_by_index(found_indices.tolist())\n",
    "found_region.paint_uniform_color([1.0, 0, 0]) # paint related points to red\n",
    "rest = pcd.select_by_index(found_indices.tolist(), invert=True)\n",
    "o3d.visualization.draw_geometries([rest,found_region])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3778aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# highlight with a heatmap\n",
    "# type the query here \n",
    "# query = [\"deathwing\"]\n",
    "# query = [\" a blue-faced, yellow-crowned, white-breasted, black-eyed, long-billed, hooked-beak, yellow-beaked, yellow-breasted, yellow-throated and black-tailed bird\"]\n",
    "\n",
    "# mouse-colored tyrannulet \n",
    "query = [[\"grey-bodied\",\"yellow-breasted\",\"black-crowned\",\n",
    "          \"white-eyed\",\"black-winged\",\"yellow-throated\",\n",
    "          \"white-breasted\",\"yellow-billed\",\"grey-headed\",\n",
    "          \"long-tailed\",\"bird\"]]\n",
    "\n",
    "# diamong firetail\n",
    "query = [[\"red-breasted\",\"black-crowned\",\"gold-winged\",\n",
    "          \"black-winged\",\"white-eyed\",\"yellow-billed\",\n",
    "          \"red-headed\",\"black-tailed\",\"long-tailed\",\n",
    "          \"white-breasted\",\"bird\"]]\n",
    "\n",
    "\n",
    "\n",
    "#query = [\"bird\"]\n",
    "#query = [[\"Mouse-colored Tyrannulet bird\"]]\n",
    "\n",
    "with torch.no_grad():\n",
    "    all_text_embeddings = []\n",
    "    for category in tqdm(query):\n",
    "        texts = clip.tokenize(category)  #tokenize\n",
    "        texts = texts.cuda()\n",
    "        text_embeddings = model.encode_text(texts)  #embed with text encoder\n",
    "        text_embeddings /= text_embeddings.norm(dim=-1, keepdim=True)\n",
    "        text_embedding = text_embeddings.mean(dim=0)\n",
    "        text_embedding /= text_embedding.norm()\n",
    "        all_text_embeddings.append(text_embedding)\n",
    "\n",
    "    all_text_embeddings = torch.stack(all_text_embeddings, dim=1)\n",
    "\n",
    "# normalizing \n",
    "fused_f = (feature[\"feat\"]/(feature[\"feat\"].norm(dim=-1, keepdim=True)+1e-5)).half()\n",
    "# calculating similarity matrix\n",
    "# similarity_matrix = torch.matmul(feature[\"feat\"].cuda(), all_text_embeddings) # \n",
    "similarity_matrix = fused_f.cuda() @ all_text_embeddings    \n",
    "\n",
    "# creating pc\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(np.asarray(filtered_point_cloud))\n",
    "pcd.colors = o3d.utility.Vector3dVector(np.asarray(filtered_point_cloud_colors))\n",
    "\n",
    "# heatmap\n",
    "cmap = plt.get_cmap('cividis')\n",
    "\n",
    "# normalize the tensor to the range [0, 1]\n",
    "normalized_tensor = (similarity_matrix - torch.min(similarity_matrix)) / (torch.max(similarity_matrix) - torch.min(similarity_matrix))\n",
    "\n",
    "colors = cmap(normalized_tensor.detach().cpu().numpy().squeeze())\n",
    "pcd_heatmap = o3d.geometry.PointCloud()\n",
    "\n",
    "pcd_heatmap.points = o3d.utility.Vector3dVector(pcd.points)\n",
    "pcd_heatmap.colors = o3d.utility.Vector3dVector(colors[:, :3])\n",
    "\n",
    "#transform heatmap to the side\n",
    "pcd_heatmap.points = o3d.utility.Vector3dVector(np.asarray(pcd.points) + [0,10,0])\n",
    "\n",
    "o3d.visualization.draw_geometries([pcd, pcd_heatmap])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad4a00d",
   "metadata": {},
   "source": [
    "# mIoU evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90b706c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCANNET_LABELS_20 = ['wall', 'floor', 'cabinet', 'bed', 'chair', 'sofa',\n",
    "                     'table', 'door', 'window', 'bookshelf', 'picture','counter', 'desk', 'curtain', 'refrigerator', 'shower curtain',\n",
    "                     'toilet', 'sink', 'bathtub', 'otherfurniture']\n",
    "UNKNOWN_ID = 255\n",
    "NO_FEATURE_ID = 256\n",
    "\n",
    "SCANNET_LABELS_20.append(query[0])\n",
    "#SCANNET_LABELS_20.append(\"bird\")\n",
    "\n",
    "CLASS_LABELS = SCANNET_LABELS_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1fb861",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    label_embeds = []\n",
    "    for category in tqdm(SCANNET_LABELS_20):\n",
    "        texts = clip.tokenize(category)  #tokenize\n",
    "        texts = texts.cuda()\n",
    "        text_embeddings = model.encode_text(texts)  #embed with text encoder\n",
    "        text_embeddings /= text_embeddings.norm(dim=-1, keepdim=True)\n",
    "        text_embedding = text_embeddings.mean(dim=0)\n",
    "        text_embedding /= text_embedding.norm()\n",
    "        label_embeds.append(text_embedding)\n",
    "\n",
    "    label_embeds = torch.stack(label_embeds, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45e721e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('classes          IoU')\n",
    "print('----------------------------')\n",
    "for i in range(N_CLASSES):\n",
    "    label_name = CLASS_LABELS[i]\n",
    "    if not isinstance(label_name, str): label_name = target_label\n",
    "    try:\n",
    "        print('{0:<14s}: {1:>5.5f}   ({2:>6d}/{3:<6d})'.format(\n",
    "                label_name,\n",
    "                class_ious[label_name][0],\n",
    "                class_ious[label_name][1],\n",
    "                class_ious[label_name][2]))\n",
    "    except:\n",
    "        print(label_name + ' error!')\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b60ed65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = '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'\n",
    "\n",
    "response = openai.Completion.create(\n",
    "  engine=\"text-davinci-003\",\n",
    "  prompt=\"Could you generate 5 visual descriptors for each of the following object classes, they are bird species: [Blue-faced Honeyeate, Diamond Firetail, Mouse-colored Tyrannulet]. The descriptors will be used for input queries for a CLIP model. The descriptors should be concise and distinct from one another. Do not focus on behavior, but purely on attributes which are recognizable by the CLIP model. The output should be in the following form, without any additional text: object class 1, visual descriptor 1.1, visual descriptor 1.2\",\n",
    "\n",
    "  temperature=0.5,\n",
    "  max_tokens=200\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa28a35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# old version of the aggregating text embeddings, it's not properly working\n",
    "def highlight_query(query, feature_type, model, distill, fused, fpc, fpcc, device):\n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        all_text_embeddings = []\n",
    "        for category in tqdm(query):\n",
    "            texts = clip.tokenize(category)  #tokenize\n",
    "            texts = texts.to(device)\n",
    "            text_embeddings = model.encode_text(texts)  #embed with text encoder\n",
    "            text_embeddings /= text_embeddings.norm(dim=-1, keepdim=True)\n",
    "            text_embedding = text_embeddings.mean(dim=0)\n",
    "            text_embedding /= text_embedding.norm()\n",
    "            all_text_embeddings.append(text_embedding)\n",
    "\n",
    "        all_text_embeddings = torch.stack(all_text_embeddings, dim=1)\n",
    "\n",
    "        \n",
    "    if feature_type == \"fused\":\n",
    "        similarity_matrix = fused.to(device) @ all_text_embeddings\n",
    "    elif feature_type == \"distilled\":\n",
    "        similarity_matrix = distill.to(device) @ all_text_embeddings\n",
    "    elif feature_type == \"ensembled\":\n",
    "        pred_fusion = fused.to(device) @ all_text_embeddings\n",
    "        pred_distill = distill.to(device) @ all_text_embeddings\n",
    "        feat_ensemble = distill.clone().half()\n",
    "        mask_ = pred_distill.max(dim=-1)[0] < pred_fusion.max(dim=-1)[0]\n",
    "        feat_ensemble[mask_] = fused_f[mask_]\n",
    "        similarity_matrix = feat_ensemble @ all_text_embeddings\n",
    "        \n",
    "    print(similarity_matrix.shape)\n",
    "    # creating pc\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(np.asarray(fpc))\n",
    "    pcd.colors = o3d.utility.Vector3dVector(np.asarray(fpcc))\n",
    "\n",
    "    # heatmap\n",
    "    cmap = plt.get_cmap('cividis')\n",
    "\n",
    "    # normalize the tensor to the range [0, 1]\n",
    "    normalized_tensor = (similarity_matrix - torch.min(similarity_matrix)) / (torch.max(similarity_matrix) - torch.min(similarity_matrix))\n",
    "\n",
    "    colors = cmap(normalized_tensor.detach().cpu().numpy().squeeze())\n",
    "    pcd_heatmap = o3d.geometry.PointCloud()\n",
    "\n",
    "    pcd_heatmap.points = o3d.utility.Vector3dVector(pcd.points)\n",
    "    pcd_heatmap.colors = o3d.utility.Vector3dVector(colors[:, :3])\n",
    "\n",
    "    #transform heatmap to the side\n",
    "    pcd_heatmap.points = o3d.utility.Vector3dVector(np.asarray(pcd.points) + [0,10,0])\n",
    "\n",
    "    o3d.visualization.draw_geometries([pcd, pcd_heatmap])\n",
    "    \n",
    "def evaluate(labelset, descriptors, feature_type, model, distill, fused, gt_ids):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        label_embeds = []\n",
    "        for category in tqdm(labelset):\n",
    "            texts = clip.tokenize(category)  #tokenize\n",
    "            texts = texts.cuda()\n",
    "            text_embeddings = model.encode_text(texts)  #embed with text encoder\n",
    "            text_embeddings /= text_embeddings.norm(dim=-1, keepdim=True)\n",
    "            text_embedding = text_embeddings.mean(dim=0)\n",
    "            text_embedding /= text_embedding.norm()\n",
    "            label_embeds.append(text_embedding)\n",
    "\n",
    "        label_embeds = torch.stack(label_embeds, dim=1)\n",
    "        \n",
    "    if feature_type == \"fused\":\n",
    "        similarity_matrix = fused.to(device) @ label_embeds\n",
    "    elif feature_type == \"distilled\":\n",
    "        similarity_matrix = distill.to(device) @ label_embeds\n",
    "    elif feature_type == \"ensembled\":\n",
    "        pred_fusion = fused.to(device) @ label_embeds\n",
    "        pred_distill = distill.to(device) @ label_embeds\n",
    "        feat_ensemble = distill.clone().half()\n",
    "        mask_ = pred_distill.max(dim=-1)[0] < pred_fusion.max(dim=-1)[0]\n",
    "        feat_ensemble[mask_] = fused_f[mask_]\n",
    "        similarity_matrix = feat_ensemble.to(device) @ label_embeds\n",
    "        \n",
    "    pred_ids = torch.max(similarity_matrix, 1)[1].detach().cpu()    \n",
    "    \n",
    "    N_CLASSES = len(labelset)\n",
    "    confusion = confusion_matrix(pred_ids, gt_ids, N_CLASSES)\n",
    "    class_ious = {}\n",
    "    class_accs = {}\n",
    "    mean_iou = 0\n",
    "    mean_acc = 0\n",
    "    \n",
    "    count = 0\n",
    "    for i in range(N_CLASSES):\n",
    "        label_name = labelset[i]\n",
    "\n",
    "        if not isinstance(label_name, str): \n",
    "            for key, value in descriptors.items():\n",
    "                if value == label_name:\n",
    "                    label_name = key\n",
    "                    \n",
    "        if (gt_ids==i).sum() == 0: # at least 1 point needs to be in the evaluation for this class\n",
    "            continue\n",
    "\n",
    "\n",
    "        class_ious[label_name] = get_iou(i, confusion)\n",
    "        class_accs[label_name] = class_ious[label_name][1] / (gt_ids==i).sum()\n",
    "        count+=1\n",
    "\n",
    "        mean_iou += class_ious[label_name][0]\n",
    "        mean_acc += class_accs[label_name]\n",
    "\n",
    "\n",
    "    mean_iou /= N_CLASSES\n",
    "    mean_acc /= N_CLASSES\n",
    "    \n",
    "    return class_ious, class_accs, mean_iou, mean_acc\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
